{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60b51bd-0144-4139-8be5-7602bad6a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 30_ngame-for-msmarco-with-hard-negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd42460-e893-40e0-a8c3-3ef5195f6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e00e5c-ff88-425d-a828-7ca5d02215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874750be-c904-447e-8754-3eefcb9586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,torch,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp\n",
    "\n",
    "from xcai.basics import *\n",
    "from xcai.models.PPP0XX import DBT009,DBT011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd23053-8908-4615-a47f-96b2039b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44292259-cc09-4bd0-96f3-08206b948924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['WANDB_PROJECT'] = 'mogicX_00-msmarco'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9b501-e911-42b1-bac1-f2a1137ff1c9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa819b08-afb0-48f3-8314-dcbd6ed99bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/scratch/scai/phd/aiz218323/outputs/mogicX/30_ngame-for-msmarco-with-hard-negatives'\n",
    "pkl_dir = '/scratch/scai/phd/aiz218323/datasets/processed/'\n",
    "\n",
    "config_file = '/scratch/scai/phd/aiz218323/datasets/msmarco/XC/configs/entity_gpt_exact.json'\n",
    "config_key = 'data_entity-gpt_exact'\n",
    "\n",
    "mname = 'sentence-transformers/msmarco-distilbert-dot-v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a47f6a6-879f-4e1d-8b4a-488f37fbe1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train_inference = False\n",
    "do_test_inference = False\n",
    "\n",
    "save_train_inference = False\n",
    "save_test_inference = False\n",
    "\n",
    "save_representation = False\n",
    "\n",
    "use_sxc_sampler, only_test = True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aee61a88-a01c-49ac-9817-b13c724a0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = f'{pkl_dir}/mogicX/msmarco_data-meta_distilbert-base-uncased'\n",
    "pkl_file = f'{pkl_file}_sxc' if use_sxc_sampler else f'{pkl_file}_xcs'\n",
    "if only_test: pkl_file = f'{pkl_file}_only-test'\n",
    "pkl_file = f'{pkl_file}.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ee793-3339-4253-840b-c205254fe36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "10a20c26-636d-4a7f-a934-65743d548894",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_inference = do_train_inference or do_test_inference or save_train_inference or save_test_inference or save_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed6a86-42c7-4e8d-a711-bfc08b69db45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed603495-d70e-4830-846f-2081b81c3150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 49s, sys: 1min 15s, total: 13min 5s\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "block = build_block(pkl_file, config_file, use_sxc_sampler, config_key, do_build=True, only_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3863052-4678-4a41-bea5-c54dffd35321",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `Negatives`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59e7984-a847-4c90-b35c-7654fef40315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, scipy.sparse as sp\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdf555f-0208-43b3-a6c2-329d2bacbd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/scai/phd/aiz218323/scratch/datasets/msmarco/negatives\"\n",
    "fname = f\"{data_dir}/cross-encoder-ms-marco-MiniLM-L-6-v2-scores.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b398c0-759f-4015-9396-89ae4c205bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_msmarco_hard_negatives(fname, query_ids):\n",
    "    with open(fname, 'rb') as file:\n",
    "        o = pickle.load(file)\n",
    "    \n",
    "    data, indices, indptr = [], [], [0]\n",
    "    for i in tqdm(query_ids):\n",
    "        if i in o:\n",
    "            data.extend(list(o[i].values()))\n",
    "            indices.extend(list(o[i].keys()))\n",
    "        indptr.append(len(data))\n",
    "    \n",
    "    return sp.csr_matrix((data, indices, indptr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5ff6bd5-94cf-4720-b876-280729c3dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = [int(i) for i in block.train.dset.data.data_info['identifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97bd2011-3e3b-474e-b10f-b786a8d0e308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c32a46cc8c473ab04991cab39f5e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg = load_msmarco_hard_negatives(fname, query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61a1c14b-f4ea-4781-9e54-8cb458aba4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_ids = [int(i) for i in block.train.dset.data.lbl_info['identifier']]\n",
    "ids = set(lbl_ids)\n",
    "meta_ids = [i for i in range(neg.shape[1]) if i not in ids]\n",
    "\n",
    "n1 = neg[:, lbl_ids]\n",
    "n2 = neg[:, meta_ids]\n",
    "\n",
    "neg_ids = lbl_ids + meta_ids\n",
    "neg = sp.hstack([n1, n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ee89fff-7c9d-4cde-8926-c00a22f2261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(f'{data_dir}/negatives_trn_X_Y.npz', neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76d79134-7f3d-44a0-b44a-7df0ce445d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sugar.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f8dd640-2296-4970-9d1b-b68b9280ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/home/scai/phd/aiz218323/scratch/datasets/msmarco/XC/raw_data/label.raw.txt'\n",
    "lbl_ids, lbl_txt = load_raw_file(fname)\n",
    "lbl_info = {k:v for k,v in zip(lbl_ids, lbl_txt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0a9f38f-64d6-45be-87b0-59fae1a3a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_txt = [lbl_info[str(i)] for i in neg_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7cf8f5de-e91a-4c64-aa6e-1dbe6cad38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_raw_file(f'{data_dir}/negatives.raw.txt', neg_ids, neg_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a13096be-cdfa-40d2-85e5-c10065df63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(f'{data_dir}/negatives_lbl_X_Y.npz', sp.csr_matrix((523598, 8841823), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b9369-3aa5-47f7-b0b3-b7f263242934",
   "metadata": {},
   "source": [
    "### `Block`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "380ed56e-8ba6-4d95-89c1-751b2531d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/scai/phd/aiz218323/scratch/datasets/msmarco/XC/configs/negatives_exact.json\"\n",
    "config_key = 'data_negatives_exact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52bfdff9-e71b-4f67-9833-bc268b46d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = f'{pkl_dir}/mogicX/msmarco_data-neg_distilbert-base-uncased'\n",
    "pkl_file = f'{pkl_file}_sxc' if use_sxc_sampler else f'{pkl_file}_xcs'\n",
    "if only_test: pkl_file = f'{pkl_file}_only-test'\n",
    "pkl_file = f'{pkl_file}.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c8045d-dcd6-4594-b9f2-493d143e4178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/scai/phd/aiz218323/datasets/processed//mogicX/msmarco_data-neg_distilbert-base-uncased_sxc.joblib'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670488e-5935-4d55-a4e2-25c248d2c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "block = build_block(pkl_file, config_file, use_sxc_sampler, config_key, do_build=False, only_test=False, use_meta_distribution=True,\n",
    "                   meta_oversample=True, n_sdata_meta_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a005e92-b69c-4e1a-9d6a-09ff50f206f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb63e2-1687-4641-9743-47858c91fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5dc03-579f-4ff8-b82e-4cde5edb1775",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9fb40c21-6ab9-4d6f-8b01-123b0234e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from xcai.losses import PKMMultiTripletFromScores\n",
    "from xcai.models.PPP0XX import XCModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c6d74059-d783-4d1a-a632-7d5fb1b68e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBT021(DBT009):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=True,\n",
    "        n_negatives:Optional[int]=10,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, margin=margin, tau=tau, apply_softmax=apply_softmax, n_negatives=n_negatives, **kwargs)\n",
    "        self.loss_fn = PKMMultiTripletFromScores(margin=margin, n_negatives=n_negatives, tau=tau, apply_softmax=apply_softmax, \n",
    "                                                 reduce='mean')\n",
    "\n",
    "    def _get_scores(self, data_repr:torch.Tensor, lbl2data_repr:torch.Tensor, neg2data_repr:Optional[torch.Tensor]=None):\n",
    "        bsz = data_repr.shape[0]\n",
    "        n_meta = neg2data_repr.shape[0] // bsz\n",
    "    \n",
    "        lbl_scores = data_repr @ lbl2data_repr.T\n",
    "\n",
    "        neg_scores = None\n",
    "        if neg2data_repr is not None:\n",
    "            neg_scores = data_repr.unsqueeze(1) @ neg2data_repr.view(bsz, n_meta, -1).transpose(1, 2)\n",
    "            neg_scores = neg_scores.squeeze(1)\n",
    "        \n",
    "        return lbl_scores if neg_scores is None else torch.hstack([lbl_scores, neg_scores])\n",
    "\n",
    "    def _get_indices(self, lbl2data_idx:torch.Tensor, neg2data_idx:Optional[torch.Tensor]=None):\n",
    "        bsz = len(lbl2data_idx)\n",
    "        n_meta = len(neg2data_idx) // bsz\n",
    "        \n",
    "        lbl_idx = torch.repeat_interleave(lbl2data_idx.unsqueeze(0), bsz, 0)\n",
    "        neg_idx = None if neg2data_idx is None else neg2data_idx.view(bsz, n_meta)\n",
    "        \n",
    "        return lbl_idx if neg_idx is None else torch.hstack([lbl_idx, neg_idx])\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "\n",
    "        neg2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        neg2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        neg2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = nn.DataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_o, data_repr = encoder(data_input_ids, data_attention_mask, \n",
    "                                    output_attentions=output_attentions, \n",
    "                                    output_hidden_states=output_hidden_states,\n",
    "                                    return_dict=return_dict)\n",
    "        \n",
    "        loss, lbl2data_repr = None, None\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask,  \n",
    "                                                output_attentions=output_attentions, \n",
    "                                                output_hidden_states=output_hidden_states,\n",
    "                                                return_dict=return_dict)\n",
    "            neg2data_repr = None\n",
    "            if neg2data_input_ids is not None:\n",
    "                neg2data_o, neg2data_repr = encoder(neg2data_input_ids, neg2data_attention_mask,\n",
    "                                                    output_attentions=output_attentions, \n",
    "                                                    output_hidden_states=output_hidden_states,\n",
    "                                                    return_dict=return_dict)\n",
    "\n",
    "                assert torch.all(neg2data_data2ptr == neg2data_data2ptr.max()), f'All datapoints should have equal negatives'\n",
    "                \n",
    "            scores, idx = self._get_scores(data_repr, lbl2data_repr, neg2data_repr), self._get_indices(lbl2data_idx, neg2data_idx)\n",
    "            loss = self.loss_fn(scores, idx, plbl2data_data2ptr, plbl2data_idx)\n",
    "\n",
    "        if not return_dict:\n",
    "            o = (data_repr, lbl2data_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_repr,\n",
    "            lbl2data_repr=lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c6e01494-1653-43e9-8a95-7a03e4d5084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT021 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-dot-v5 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DBT021.from_pretrained(mname, bsz=1000, tn_targ=5000, margin=0.3, tau=0.1, n_negatives=10, \n",
    "                               apply_softmax=True, use_encoder_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76efc7-5fc0-4724-a8f0-f8a7b1f5620d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eeae07b2-1d49-4143-bd5b-acc23999cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=300,\n",
    "    predict_with_representation=True,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    adam_epsilon=1e-6,                                                                                                                                          warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=25,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=2,\n",
    "    maximum_cluster_size=1600,\n",
    "\n",
    "    metric_for_best_model='P@1',\n",
    "    load_best_model_at_end=True,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd744581-0643-458d-8dcb-bb7cf4431501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20b25d7e-7c0e-43ee-b906-37f393857709",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecReclMrr(block.test.dset.n_lbl, block.test.data_lbl_filterer,\n",
    "                     pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200], mk=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d2f24546-a843-4d71-a0ad-b6c35ab015ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learn = XCLearner(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd385a7f-6edd-4034-b6e4-46f0179b9e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "44406b16-7fc9-41b3-960e-b3fde5311b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = learn.get_train_dataloader()\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8ff3df18-6697-42cb-9425-7d6f74e09616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'neg2data_idx', 'neg2data_data2ptr', 'neg2data_input_ids', 'neg2data_attention_mask'])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d95663ec-62eb-4ae8-a3a0-4893594fb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    o = model(**batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "619905f0-1903-4ed5-8e12-4ba79c314e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.to(model.device)\n",
    "o = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c57a8201-4297-4621-bfe3-23643ebf4a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XCModelOutput(loss=tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>), logits=None, lm_loss=None, dr_loss=None, data_repr=tensor([[ 0.0210, -0.0089, -0.0497,  ...,  0.0260,  0.0203,  0.0314],\n",
       "        [ 0.0080, -0.0119, -0.0603,  ...,  0.0212,  0.0167,  0.0730],\n",
       "        [ 0.0382,  0.0116, -0.0456,  ...,  0.0267, -0.0068,  0.0473],\n",
       "        ...,\n",
       "        [ 0.0305, -0.0044, -0.0332,  ...,  0.0222,  0.0502,  0.0704],\n",
       "        [ 0.0059,  0.0152, -0.0177,  ...,  0.0201, -0.0265,  0.0305],\n",
       "        [ 0.0344, -0.0250, -0.0396,  ...,  0.0449,  0.0415,  0.0571]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_repr=tensor([[ 0.0232, -0.0060, -0.0577,  ...,  0.0383,  0.0307,  0.0272],\n",
       "        [ 0.0512, -0.0025, -0.0409,  ...,  0.0580,  0.0047,  0.0745],\n",
       "        [ 0.0427,  0.0073, -0.0446,  ...,  0.0403,  0.0536,  0.0543],\n",
       "        ...,\n",
       "        [ 0.0419, -0.0041, -0.0188,  ...,  0.0378,  0.0434,  0.0771],\n",
       "        [-0.0034,  0.0121,  0.0002,  ...,  0.0340,  0.0228,  0.0703],\n",
       "        [ 0.0299, -0.0115, -0.0178,  ...,  0.0324,  0.0484,  0.0375]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), data_embed=None, lbl2data_embed=None, data_hidden_states=None, data_attentions=None, data_cross_attentions=None, lbl2data_hidden_states=None, lbl2data_attentions=None, lbl2data_cross_attentions=None)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ee19c-38b0-48e4-8613-54b8d447cccf",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67be8d-d2b0-40d2-a772-8d068ad99a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    output_dir = '/scratch/scai/phd/aiz218323/outputs/mogicX/30_ngame-for-msmarco-with-hard-negatives'\n",
    "\n",
    "    config_file = '/scratch/scai/phd/aiz218323/datasets/msmarco/XC/configs/negatives_exact.json.json'\n",
    "    config_key = 'data_negatives_exact'\n",
    "    \n",
    "    mname = 'sentence-transformers/msmarco-distilbert-cos-v5'\n",
    "\n",
    "    input_args = parse_args()\n",
    "\n",
    "    pkl_file = f'{input_args.pickle_dir}/mogicX/msmarco_data-neg_distilbert-base-uncased'\n",
    "    pkl_file = f'{pkl_file}_sxc' if input_args.use_sxc_sampler else f'{pkl_file}_xcs'\n",
    "    if input_args.only_test: pkl_file = f'{pkl_file}_only-test'\n",
    "    pkl_file = f'{pkl_file}.joblib'\n",
    "\n",
    "    do_inference = input_args.do_train_inference or input_args.do_test_inference or input_args.save_train_prediction or input_args.save_test_prediction or input_args.save_representation\n",
    "\n",
    "    os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "    block = build_block(pkl_file, config_file, input_args.use_sxc_sampler, config_key, do_build=input_args.build_block, \n",
    "                        only_test=input_args.only_test, use_meta_distribution=True, meta_oversample=True, n_sdata_meta_samples=10)\n",
    "\n",
    "    args = XCLearningArguments(\n",
    "        output_dir=output_dir,\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=800,\n",
    "        per_device_eval_batch_size=800,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=300,\n",
    "        predict_with_representation=True,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        adam_epsilon=1e-6,                                                                                                                                          warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-4,\n",
    "    \n",
    "        group_by_cluster=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "    \n",
    "        metric_for_best_model='P@1',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "    \n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None,\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    def model_fn(mname, bsz):\n",
    "        model = DBT009.from_pretrained(mname, bsz=bsz, tn_targ=5000, margin=0.3, tau=0.1, n_negatives=10, \n",
    "                                       apply_softmax=True, use_encoder_parallel=True)\n",
    "        return model\n",
    "    \n",
    "    def init_fn(model): \n",
    "        model.init_dr_head()\n",
    "\n",
    "    metric = PrecReclMrr(block.test.dset.n_lbl, block.test.data_lbl_filterer,\n",
    "                     pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200], mk=[5, 10, 20])\n",
    "\n",
    "    bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "    model = load_model(args.output_dir, model_fn, {\"mname\": mname, \"bsz\": bsz}, init_fn, do_inference=do_inference, use_pretrained=input_args.use_pretrained)\n",
    "    \n",
    "    learn = XCLearner(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=block.train.dset,\n",
    "        eval_dataset=block.test.dset,\n",
    "        data_collator=block.collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "    \n",
    "    main(learn, input_args, n_lbl=block.test.dset.n_lbl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced4774-3de8-4275-938e-c034b164cf35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
