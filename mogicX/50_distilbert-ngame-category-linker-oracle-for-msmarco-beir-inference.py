# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_ngame-for-msmarco-inference.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 3
import os

import torch,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse
from typing import Optional, List
from tqdm.auto import tqdm

from xcai.misc import *
from xcai.basics import *

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 5
os.environ["WANDB_PROJECT"] = "02_upma-msmarco-gpt-concept-substring"

DATASETS = [
    "arguana",
    "msmarco",
    "climate-fever",
    "dbpedia-entity",
    "fever",
    "fiqa",
    "hotpotqa",
    "nfcorpus",
    "nq",
    "quora",
    "scidocs",
    "scifact",
    "webis-touche2020",
    "trec-covid",
    "cqadupstack/android",
    "cqadupstack/english",
    "cqadupstack/gaming",
    "cqadupstack/gis",
    "cqadupstack/mathematica",
    "cqadupstack/physics",
    "cqadupstack/programmers",
    "cqadupstack/stats",
    "cqadupstack/tex",
    "cqadupstack/unix",
    "cqadupstack/webmasters",
    "cqadupstack/wordpress"
]

def early_fusion_beir_inference(output_dir:str, input_args:argparse.ArgumentParser, mname:str, linker_dir:str, 
                                datasets:Optional[List]=None, raw_dir_name:Optional[str]="raw_data", 
                                metric_dir_name:Optional[str]="metrics"):
    
    metric_dir = f"{output_dir}/{metric_dir_name}"
    os.makedirs(metric_dir, exist_ok=True)

    input_args.only_test = input_args.do_test_inference = True

    datasets = BEIR_DATASETS if datasets is None else datasets
    for dataset in tqdm(datasets):
        print(dataset)

        config_file = f"/data/datasets/beir/{dataset}/XC/configs/data.json"
        train_dset, test_dset = load_early_fusion_block(dataset, config_file, input_args)

        dataset = dataset.replace("/", "-")
        linker_dir_name, cross_name = os.path.basename(linker_dir.rstrip("/")), raw_dir_name.rstrip("/")
        linker_dir_name = f"{linker_dir_name}/{cross_name.split('/')[1]}" if "/" in cross_name else linker_dir_name

        data_file = f"{linker_dir}/{raw_dir_name}/test_{dataset}.raw.csv"
        if not os.path.exists(data_file): continue

        data_info = load_info(f"{input_args.pickle_dir}/{linker_dir_name}/{dataset}.joblib", 
                              data_file, mname, sequence_length=128)
        test_dset = SXCDataset(SMainXCDataset(data_info=data_info, data_lbl=test_dset.data.data_lbl, lbl_info=test_dset.data.lbl_info))

        input_args.prediction_suffix = dataset
        trn_repr, tst_repr, lbl_repr, trn_pred, tst_pred, trn_metric, tst_metric = early_fusion_run(output_dir, input_args, mname, test_dset, train_dset)
        with open(f"{metric_dir}/{dataset}.json", "w") as file:
            json.dump({dataset: tst_metric}, file, indent=4)

    collate_beir_metrics(metric_dir)


def additional_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--raw_dir_name", type=str)
    parser.add_argument("--metric_dir_name", type=str)
    return parser.parse_known_args()[0]

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 20
if __name__ == '__main__':
    input_args = parse_args()
    extra_args = additional_args()

    output_dir = "/data/outputs/mogicX/50_distilbert-ngame-category-linker-oracle-for-msmarco-008"

    input_args.use_sxc_sampler = True
    input_args.pickle_dir = "/home/aiscuser/scratch1/datasets/processed/"
    mname = "distilbert-base-uncased"

    # raw_dir_name = "raw_data"
    # metric_dir_name = "metrics"

    # raw_dir_name = "cross_raw_data/msmarco-substring"
    # metric_dir_name = "cross_metrics/msmarco-substring"

    raw_dir_name, metric_dir_name = extra_args.raw_dir_name, extra_args.metric_dir_name

    linker_dir = "/data/outputs/mogicX/47_msmarco-gpt-category-linker-007"

    early_fusion_beir_inference(output_dir, input_args, mname, linker_dir, raw_dir_name=raw_dir_name, metric_dir_name=metric_dir_name, 
                                datasets=DATASETS)

